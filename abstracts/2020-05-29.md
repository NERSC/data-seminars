# Simulation-based and label-free deep learning for science
## Ben Nachmann (Lawrence Berkeley National Laboratory)

## Abstract 
Precise scientific analysis in many areas of science is possible because of complex simulations that connect fundamental theories to observable quantities. These simulations have been paired with multivariate methods for many years in search of new fundamental and emergent structure in nature.  Deep learning tools hold great promise to qualitatively change this paradigm by allowing for holistic analysis of data in its natural hyperdimensionality with thousands or millions of features instead of up to tens of features.  These tools are not yet broadly used for all areas of data analysis because of the traditional dependence on simulations.  In this talk, I will discuss how we can change this paradigm in order to exploit the new features of deep learning.  In particular, I will show how neural networks can be used to (1) overcome the challenge of high-dimensional probability density modeling and (2) learn directly from (unlabeled) data to perform hypothesis tests that go beyond any existing analysis methods.  The example for (1) will be full phase space unfolding (deconvolution) and the example for (2) will be anomaly detection.  The talk will include a discussion of uncertainties associated with deep learning-based analyses.  These ideas are starting to become a reality: the first deep learning weakly supervised anomaly detection search has recently been made public by the ATLAS Collaboration at the LHC.  While my examples will primarily draw from collider physics, the techniques are more broadly applicable and I am happy to discuss extensions and applications to your science domain.

## Bios
Benjamin Nachman is currently Chamberlain Fellow at the Lawrence Berkeley National Laboratory and a member of the ATLAS Collaboration at CERN. He obtained his PhD in Physics, with a minor in Statistics, from Stanford University.
