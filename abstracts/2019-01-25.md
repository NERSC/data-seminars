## Hierarchical Deep Learning for Long-term Sequence Generation
### Stephan Zheng (Salesforce Research)

Deep learning is a powerful framework for representation learning, and has proven itself in computer vision, natural language processing and other domains. However, it is still challenging to apply deep learning to structured prediction tasks on spatiotemporal data, e.g., multi-agent human tracking data and physical systems. Here, a key challenge is long-term sequence generation: given an initial state, how can we extrapolate into the far future when the underlying dynamics is nonlinear? 

In this talk, I will first present a family of hierarchical deep learning methods that significantly improves on this task, including on data from real-life sports tracking and synthetic dynamical systems. These include single and multi-agent hierarchical neural networks that both predict long-term goals and short-term actions, learned using auxiliary goal labels. I will then show how multi-resolution non-autoregressive sequence models can learn to forecast by joint extrapolation and interpolation in a completely unsupervised way. Finally, I will present Tensor-Train RNNs, which can efficiently learn long-term forecasting over nonlinear dynamics.
