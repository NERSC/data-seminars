# Deep learning for PDEs, and scientific computing with JAX
## Stephan Hoyer (Google)

## Abstract 
This talk will give an overview of how deep learning can be combined with traditional numerical methods to create improved methods for scientific computing. I will highlight two recent examples from my research: using deep learning to improve discretizations for solving partial differential equations [1], and using deep learning to reparameterize optimization landscapes for PDE constrained structural optimization [2]. I will also briefly introduce JAX [3], an open source library from Google for composable transformations of Python/NumPy programs, including automatic differentiation, vectorization and JIT compilation for accelerators. JAX is particularly suitable for scientific applications, including hybrid machine learning / simulation codes.

[1] Bar-Sinai*, Y., Hoyer*, S., Hickey, J. & Brenner, M. P. Learning data-driven discretizations for partial differential equations. Proceedings of the National Academy of Sciences 201814058 (2019). doi:10.1073/pnas.1814058116 [2] Hoyer, S., Sohl-Dickstein, J. & Greydanus, S. Neural reparameterization improves structural optimization. arXiv [cs.LG] (2019). https://arxiv.org/abs/1909.04240 [3] https://github.com/google/jax


## Bio
Stephan is a researcher and software engineer at Google on the Accelerated Sciences team (https://research.google/teams/applied-science/gas/), where he works on applications of machine learning to scientific computing and the physical sciences. Before Google, he worked on machine learning for weather forecasting at The Climate Corporation and completed a Physics PhD at UC Berkeley. He is also a frequent contributor to open source projects in the Python scientific computing stack, including NumPy, Dask, Xarray, and JAX.
